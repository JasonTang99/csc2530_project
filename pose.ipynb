{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import open3d as o3d\n",
    "from open3d.visualization import draw_geometries\n",
    "\n",
    "from process_bag import get_images\n",
    "from utils import get_o3d_intrinsics, colordepth_to_rgbd, rgbd_to_pcd, remove_outliers\n",
    "\n",
    "depth_intrinsics, color_intrinsics = get_o3d_intrinsics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chessboard size\n",
    "cb_counts = (4, 7)\n",
    "cb_scale = 5\n",
    "cb_size = 0.033 * cb_scale\n",
    "\n",
    "# Rendering settings\n",
    "voxel_size = 0.02\n",
    "camera_size = 2 * cb_size\n",
    "origin_size = 4 * cb_size\n",
    "\n",
    "kwargs = dict(\n",
    "    zoom=0.5,\n",
    "    front=[0.0, 0.0, -1.0],\n",
    "    lookat=[0.0, 0.0, 0.0],\n",
    "    up=[1.0, 0, 0],\n",
    ")\n",
    "\n",
    "data_name = \"books_2\"\n",
    "data_folder = f\"data/{name}/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/Process Data\n",
    "def get_imgs(color_fp, depth_fp, start_idx, end_idx, align=True):\n",
    "    if os.path.exists(color_fp) and os.path.exists(depth_fp):\n",
    "        color_imgs = np.load(color_fp)\n",
    "        depth_imgs = np.load(depth_fp)\n",
    "    else:\n",
    "        color_imgs = []\n",
    "        depth_imgs = []\n",
    "        fps = sorted(glob.glob(f'{data_folder}/bags/*.bag'))\n",
    "        for i, fp in enumerate(fps):\n",
    "            if not os.path.exists(fp):\n",
    "                continue\n",
    "            print(f\"Processing bag {i+1}/{len(fps)} {fp}\")\n",
    "            color_img, depth_img = get_images(\n",
    "                start_idx=start_idx,\n",
    "                end_idx=end_idx,\n",
    "                bag_fp=fp,\n",
    "                align=align,\n",
    "                median=True\n",
    "            )\n",
    "            color_imgs.append(color_img)\n",
    "            depth_imgs.append(depth_img)\n",
    "        color_imgs = np.stack(color_imgs)\n",
    "        depth_imgs = np.stack(depth_imgs)\n",
    "        np.save(color_fp, color_imgs)\n",
    "        np.save(depth_fp, depth_imgs)\n",
    "    return color_imgs, depth_imgs\n",
    "\n",
    "color_imgs, depth_imgs = get_imgs(\n",
    "    os.path.join(data_folder, \"color.npy\"),\n",
    "    os.path.join(data_folder, \"depth.npy\"),\n",
    "    0, 30\n",
    ")\n",
    "color_imgs_single, depth_imgs_single = get_imgs(\n",
    "    os.path.join(data_folder, \"color_single.npy\"),\n",
    "    os.path.join(data_folder, \"depth_single.npy\"),\n",
    "    5, 6\n",
    ")\n",
    "color_imgs.shape, depth_imgs.shape, color_imgs_single.shape, depth_imgs_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_corners(gray, corners, size=6):\n",
    "    corners2 = cv2.cornerSubPix(gray,corners,(size, size),(-1,-1),criteria)\n",
    "    # Arrange corner order\n",
    "    x1, y1 = corners2[0, 0]\n",
    "    x2, y2 = corners2[-1, 0]\n",
    "    # print(x1, x2, y1, y2)\n",
    "    flip = False\n",
    "    if x1 > x2 or y1 < y2:\n",
    "        corners2 = corners2[::-1]\n",
    "        flip = True\n",
    "    return corners2, flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.01)\n",
    "\n",
    "# Define object points\n",
    "objp = np.zeros((cb_counts[0]*cb_counts[1],3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:cb_counts[0],0:cb_counts[1]].T.reshape(-1,2)\n",
    "objp *= cb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "used_idxs = [] # Indices of images used\n",
    "for i in tqdm(range(color_imgs.shape[0])):\n",
    "    gray = cv2.cvtColor(color_imgs[i], cv2.COLOR_RGB2GRAY)\n",
    "    gray_single = cv2.cvtColor(color_imgs_single[i], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find and refine corners\n",
    "    flags = cv2.CALIB_CB_EXHAUSTIVE + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "    ret, corners = cv2.findChessboardCornersSB(gray_single, cb_counts, flags=flags)\n",
    "    if ret == False:\n",
    "        ret, corners = cv2.findChessboardCornersSB(gray, cb_counts, flags=flags)\n",
    "    if ret == True:\n",
    "        corners, flip = finetune_corners(gray, corners)\n",
    "        if not flip:\n",
    "            print(\"Flipped\", i)\n",
    "        used_idxs.append(i)\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(used_idxs)\n",
    "print(f\"Found {n} images with checkerboard corners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_imgs = color_imgs[used_idxs]\n",
    "depth_imgs = depth_imgs[used_idxs]\n",
    "\n",
    "color_imgs.shape, depth_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs, titles=None, width=2):\n",
    "    if titles is not None: assert len(imgs) == len(titles)\n",
    "    f = lambda x: (x + width - 1) // width\n",
    "    n = len(imgs)\n",
    "    fig, axs = plt.subplots(f(n), width, figsize=(16, 6*f(n)))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if i >= n: break\n",
    "        ax.imshow(imgs[i])\n",
    "        if titles is not None: \n",
    "            ax.set_title(titles[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot corners\n",
    "plot_data = []\n",
    "for i in range(n):\n",
    "    try:\n",
    "        img_tmp = cv2.drawChessboardCorners(\n",
    "            color_imgs[i].copy(), cb_counts, imgpoints[i], True)\n",
    "        \n",
    "        # Calculate reprojection error\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "            [objpoints[i]], [imgpoints[i]], img_tmp.shape[:-1][::-1], None, None)\n",
    "        mat_err = np.linalg.norm(mtx - color_intrinsics.intrinsic_matrix)\n",
    "        title = f\"Image {i} {mat_err:.2f}\"\n",
    "        plot_data.append((mat_err, img_tmp, title, i))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by error and take top k\n",
    "k = 10\n",
    "plot_data.sort(key=lambda x: x[0], reverse=True)\n",
    "plot_filt = plot_data[:k]\n",
    "plot_imgs = [x[1] for x in plot_filt]\n",
    "plot_titles = [x[2] for x in plot_filt]\n",
    "plot_idxs = [x[3] for x in plot_filt]\n",
    "show_imgs(plot_imgs, plot_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, _ = color_imgs[0].shape\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "    objpoints, imgpoints, (w, h), None, None)\n",
    "\n",
    "estimated_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "estimated_intrinsics.intrinsic_matrix = mtx\n",
    "\n",
    "print(color_intrinsics.intrinsic_matrix)\n",
    "print()\n",
    "print(estimated_intrinsics.intrinsic_matrix)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, corners, imgpts):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    corner = (int(corner[0]), int(corner[1]))\n",
    "    imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "\n",
    "    img = cv2.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the negative z axis\n",
    "axis = np.float32([[1,0,0], [0,1,0], [0,0,-1]]).reshape(-1,3) * cb_size * 4\n",
    "\n",
    "rvecs_lst = []\n",
    "tvecs_lst = []\n",
    "plot_coords = []\n",
    "# for i in tqdm(range(n)):\n",
    "for i in plot_idxs:\n",
    "    try:\n",
    "        img_tmp = color_imgs[i].copy()\n",
    "\n",
    "        # Find the rotation and translation vectors.\n",
    "        rvec = rvecs[i].copy()\n",
    "        tvec = tvecs[i].copy()\n",
    "        # retval, rvec, tvec, inliers = cv2.solvePnPRansac(\n",
    "        #     objp, imgpoints[i], mtx, dist, \n",
    "        #     rvec=rvec, \n",
    "        #     tvec=tvec,\n",
    "        #     useExtrinsicGuess=True,\n",
    "        #     iterationsCount=1000,\n",
    "        #     reprojectionError=8, \n",
    "        #     confidence=0.99\n",
    "        # )\n",
    "        retval, rvec, tvec = cv2.solvePnP(\n",
    "            objp, imgpoints[i], mtx, dist, \n",
    "            rvec=rvec, \n",
    "            tvec=tvec,\n",
    "            useExtrinsicGuess=True,\n",
    "        )\n",
    "        # Check allclose\n",
    "        # print(i, np.allclose(rvec, rvecs[i]), np.allclose(tvec, tvecs[i]))\n",
    "\n",
    "        # project 3D points to image plane\n",
    "        imgpts, _ = cv2.projectPoints(axis, rvec, tvec, mtx, dist)\n",
    "        img_tmp = draw_axis(img_tmp, imgpoints[i], imgpts)\n",
    "        plot_coords.append(img_tmp)\n",
    "\n",
    "        rvecs_lst.append(rvec)\n",
    "        tvecs_lst.append(tvec)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i1, i2 = 128, 110\n",
    "# idx1, idx2 = plot_idxs.index(i1), plot_idxs.index(i2)\n",
    "# # show_imgs([plot_imgs[i], plot_imgs[i+1], plot_coords[i], plot_coords[i+1]])\n",
    "# show_imgs([plot_imgs[idx1], plot_coords[idx1], plot_imgs[idx2], plot_coords[idx2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_imgs([plot_imgs[i] for i in plot_idxs], plot_titles)\n",
    "show_imgs(plot_coords, plot_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn lists into extrinsic parameters\n",
    "# rvecs = np.array(rvecs_lst)\n",
    "# tvecs = np.array(tvecs_lst)\n",
    "rvecs = np.array(rvecs)\n",
    "tvecs = np.array(tvecs)\n",
    "\n",
    "# Turn into 4x4 extrinsic matrices\n",
    "w2c_exts = np.zeros((len(rvecs), 4, 4))\n",
    "c2w_exts = np.zeros((len(rvecs), 4, 4))\n",
    "for i in range(len(rvecs)):\n",
    "    R, _ = cv2.Rodrigues(rvecs[i])\n",
    "    w2c_exts[i, :3, :3] = R\n",
    "    w2c_exts[i, :3, 3] = tvecs[i].T\n",
    "    w2c_exts[i, 3, 3] = 1\n",
    "\n",
    "    # world to camera -> camera to world\n",
    "    c2w_exts[i] = np.linalg.inv(w2c_exts[i])\n",
    "c2w_exts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=origin_size, origin=[0,0,0])\n",
    "\n",
    "# Draw camera locations and rotations\n",
    "cameras = []\n",
    "pcds_align = []\n",
    "pcds_full = []\n",
    "\n",
    "intrinsics = color_intrinsics\n",
    "# intrinsics = estimated_intrinsics\n",
    "for c2w_ext, color_img, depth_img in zip(c2w_exts, color_imgs, depth_imgs):\n",
    "    # Get the RGBD image\n",
    "    rgbd_img = colordepth_to_rgbd(color_img, depth_img)\n",
    "    \n",
    "    # Create a camera frame\n",
    "    camera = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "        size=camera_size, origin=[0,0,0])\n",
    "    camera.transform(c2w_ext)\n",
    "\n",
    "    # Create a pointcloud\n",
    "    pcd = rgbd_to_pcd(rgbd_img, intrinsics)\n",
    "    # Scale the pointcloud\n",
    "    pcd.scale(cb_scale, center=[0,0,0])\n",
    "    pcds_full.append(pcd)\n",
    "\n",
    "    # Downsample and Align\n",
    "    pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "    pcd.transform(c2w_ext)\n",
    "    \n",
    "    # Add to lists\n",
    "    cameras.append(camera)\n",
    "    pcds_align.append(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries(\n",
    "    pcds_align + [origin] + cameras, \n",
    "    **kwargs\n",
    ")\n",
    "# o3d.visualization.draw_geometries(\n",
    "#     pcds_full + [origin] + cameras,\n",
    "#     **kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries(\n",
    "    [origin] + cameras, \n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pointclouds and extrinsics\n",
    "!mkdir -p {data_folder}/plys\n",
    "!rm -rf {data_folder}/plys/*\n",
    "\n",
    "for i, (pcd, c2w_ext) in enumerate(zip(pcds_full, c2w_exts)):\n",
    "    fp = f\"{data_folder}/plys/pcd_{i:03}.ply\"\n",
    "    o3d.io.write_point_cloud(fp, pcd)\n",
    "\n",
    "np.save(f\"{data_folder}/c2w_extrinsics.npy\", c2w_exts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoise Pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pointclouds and extrinsics\n",
    "pcds_full = []\n",
    "for fp in sorted(glob.glob(f\"{data_folder}/plys/pcd_*.ply\")):\n",
    "    pcds_full.append(o3d.io.read_point_cloud(fp))\n",
    "\n",
    "c2w_exts = np.load(f\"{data_folder}/c2w_extrinsics.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed and split into train, val, test\n",
    "np.random.seed(0)\n",
    "n = len(pcds_full)\n",
    "idxs = np.arange(n)\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "train_percent, val_percent, test_percent = 0.6, 0.2, 0.2\n",
    "train_idxs = idxs[:int(n*train_percent)]\n",
    "val_idxs = idxs[int(n*train_percent):int(n*(train_percent+val_percent))]\n",
    "test_idxs = idxs[int(n*(train_percent+val_percent)):]\n",
    "\n",
    "pcds_train = [pcds_full[i] for i in train_idxs]\n",
    "pcds_val = [pcds_full[i] for i in val_idxs]\n",
    "pcds_test = [pcds_full[i] for i in test_idxs]\n",
    "\n",
    "c2w_exts_train = c2w_exts[train_idxs]\n",
    "c2w_exts_val = c2w_exts[val_idxs]\n",
    "c2w_exts_test = c2w_exts[test_idxs]\n",
    "\n",
    "len(pcds_train), len(pcds_val), len(pcds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def o3d_vis(pcds, c2w_exts, align=True, use_kwargs=True, both=False):\n",
    "    # Test Alignment\n",
    "    pcds_align = []\n",
    "    cameras = []\n",
    "    for i in range(len(pcds)):\n",
    "        pcd = copy.deepcopy(pcds[i])\n",
    "        c2w_ext = c2w_exts[i]\n",
    "\n",
    "        if align:\n",
    "            pcd.transform(c2w_ext)\n",
    "        pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "        pcds_align.append(pcd)\n",
    "\n",
    "        # Camera frame\n",
    "        camera = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "            size=camera_size, origin=[0,0,0])\n",
    "        camera.transform(c2w_ext)\n",
    "        cameras.append(camera)\n",
    "\n",
    "    # Make origin a 3d box\n",
    "    origin = o3d.geometry.TriangleMesh.create_box(\n",
    "        width=origin_size, height=origin_size, depth=origin_size)\n",
    "    origin.paint_uniform_color([0.9, 0.1, 0.1])\n",
    "    origin.translate([0,0,-origin_size/2])\n",
    "\n",
    "    # origin coords\n",
    "    origin = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "        size=2, origin=[0,0,0])\n",
    "    origin2 = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "        size=2, origin=[0,0,0])\n",
    "    origin2.rotate(R=np.array([[-1,0,0],[0,-1,0],[0,0,-1]]), center=[0,0,0])\n",
    "\n",
    "    origins = [origin]\n",
    "    if both:\n",
    "        origins = [origin, origin2]\n",
    "\n",
    "    if use_kwargs:\n",
    "        o3d.visualization.draw_geometries(pcds_align + cameras + origins, \n",
    "        **kwargs)\n",
    "    else:\n",
    "        o3d.visualization.draw_geometries(pcds_align + cameras + origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_train, c2w_exts_train)\n",
    "# o3d_vis(pcds_val, c2w_exts_val)\n",
    "# o3d_vis(pcds_test, c2w_exts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_neighbors = 20\n",
    "std_ratio = 0.25\n",
    "nb_points = 25\n",
    "radius = 0.15\n",
    "\n",
    "voxel_size = 0.045\n",
    "\n",
    "def clean_pcds(pcds_full, c2w_exts, voxel_size=None):\n",
    "    pcds_clean = []\n",
    "    for i in tqdm(range(len(pcds_full))):\n",
    "        clean = pcds_full[i]\n",
    "        if voxel_size is not None:\n",
    "            clean = clean.voxel_down_sample(voxel_size=voxel_size)\n",
    "        \n",
    "        clean = remove_outliers(\n",
    "            clean,\n",
    "            nb_neighbors=nb_neighbors,\n",
    "            std_ratio=std_ratio,\n",
    "            nb_points=nb_points,\n",
    "            radius=radius\n",
    "        )\n",
    "        clean.transform(c2w_exts[i])\n",
    "        pcds_clean.append(clean)        \n",
    "    return pcds_clean\n",
    "\n",
    "pcds_clean_train = clean_pcds(pcds_train, c2w_exts_train, voxel_size=voxel_size)\n",
    "pcds_clean_val = clean_pcds(pcds_val, c2w_exts_val, voxel_size=voxel_size)\n",
    "pcds_clean_test = clean_pcds(pcds_test, c2w_exts_test, voxel_size=voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean = pcds_train[0]\n",
    "# print(clean)\n",
    "\n",
    "# nb_neighbors = 20\n",
    "# std_ratio = 0.25\n",
    "# nb_points = 25\n",
    "# radius = 0.15\n",
    "\n",
    "# voxel_size = 0.045\n",
    "\n",
    "# # Downsample\n",
    "# clean = clean.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "# clean = remove_outliers(\n",
    "#     clean,\n",
    "#     nb_neighbors=nb_neighbors,\n",
    "#     std_ratio=std_ratio,\n",
    "#     nb_points=nb_points,\n",
    "#     radius=radius\n",
    "# )\n",
    "# clean\n",
    "# draw_geometries([clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_clean_train, c2w_exts_train, align=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align Pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the normals\n",
    "for pcds, c2w_exts in zip(\n",
    "        [pcds_clean_train, pcds_clean_val, pcds_clean_test],\n",
    "        [c2w_exts_train, c2w_exts_val, c2w_exts_test]\n",
    "    ):\n",
    "    for i in range(len(pcds)):\n",
    "        pcd = pcds[i]\n",
    "        # pcd.transform(c2w_exts[i])\n",
    "        pcd.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=0.1, max_nn=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_clean_train, c2w_exts_train, align=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define crop bounds\n",
    "# end_1 = np.array([0.04, -0.62, -0.55]) * cb_scale\n",
    "# end_2 = np.array([1.3, 0.5, 0.35]) * cb_scale\n",
    "\n",
    "end_1 = np.array([-0.4, -0.62, -0.55]) * cb_scale\n",
    "end_2 = np.array([0.8, 0.4, 0.35]) * cb_scale\n",
    "\n",
    "coord_1 = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.5, origin=[0,0,0])\n",
    "coord_2 = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.5, origin=[0,0,0])\n",
    "coord_1.translate(end_1)\n",
    "coord_2.translate(end_2)\n",
    "\n",
    "bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=end_1, max_bound=end_2)\n",
    "\n",
    "pcds_crops = [[], [], []]\n",
    "for i, pcds_clean in enumerate([pcds_clean_train, pcds_clean_val, pcds_clean_test]):\n",
    "    for pcd in pcds_clean:\n",
    "        pcd_tmp = copy.deepcopy(pcd)\n",
    "        pcds_crops[i].append(pcd.crop(bbox))\n",
    "\n",
    "o3d.visualization.draw_geometries(pcds_crops[0] + [coord_1, coord_2], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse the point clouds and draw bounding box\n",
    "pcd_fused = o3d.geometry.PointCloud()\n",
    "for pcd in pcds_crops[0]:\n",
    "    pcd_fused += pcd\n",
    "\n",
    "pcd_fused = pcd_fused.voxel_down_sample(voxel_size=voxel_size)\n",
    "bbox = pcd_fused.get_axis_aligned_bounding_box()\n",
    "bbox.color = (1, 0, 0)\n",
    "o3d.visualization.draw_geometries([pcd_fused, bbox], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out points that are too bright or too gray\n",
    "color_thresh = 0.5\n",
    "gray_thresh = 0.07\n",
    "\n",
    "pcds_filt = []\n",
    "for i in range(len(pcds_crop)):\n",
    "    pcd = pcds_crop[i]\n",
    "    colors = np.asarray(pcd.colors)\n",
    "    \n",
    "    color_idxs = np.where(np.mean(colors, axis=1) > color_thresh)[0]\n",
    "    gray_idxs = np.where(np.max(colors, axis=1) - np.min(colors, axis=1) < gray_thresh)[0]\n",
    "    idxs = np.union1d(color_idxs, gray_idxs)\n",
    "    print(len(idxs))\n",
    "    pcd_filt = pcd.select_by_index(\n",
    "        idxs,\n",
    "        invert=True\n",
    "    )\n",
    "    pcds_filt.append(pcd_filt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pcds_filt + [coord_1, coord_2], **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiway Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://www.open3d.org/docs/latest/tutorial/Advanced/multiway_registration.html\n",
    "def pairwise_registration(\n",
    "        source, target, max_correspondence_distance_coarse,\n",
    "        max_correspondence_distance_fine\n",
    "    ):\n",
    "    # print(\"Apply point-to-plane ICP\")\n",
    "    # Coarse ICP starting with identity matrix\n",
    "    icp_coarse = o3d.pipelines.registration.registration_icp(\n",
    "        source, \n",
    "        target, \n",
    "        max_correspondence_distance_coarse, \n",
    "        init = np.identity(4),\n",
    "        estimation_method = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    )\n",
    "    # Fine ICP using the result of coarse ICP as initialization\n",
    "    icp_fine = o3d.pipelines.registration.registration_icp(\n",
    "        source, \n",
    "        target, \n",
    "        max_correspondence_distance_fine,\n",
    "        init = icp_coarse.transformation,\n",
    "        estimation_method = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    )\n",
    "    \n",
    "    # Return the transformation matrix and information matrix\n",
    "    transformation_icp = icp_fine.transformation\n",
    "    information_icp = o3d.pipelines.registration.get_information_matrix_from_point_clouds(\n",
    "        source, target, max_correspondence_distance_fine,\n",
    "        icp_fine.transformation)\n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def full_registration(\n",
    "        pcds, max_correspondence_distance_coarse,\n",
    "        max_correspondence_distance_fine\n",
    "    ):\n",
    "    pose_graph = o3d.pipelines.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    for source_id in tqdm(range(n_pcds)):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(\n",
    "                pcds[source_id], \n",
    "                pcds[target_id], \n",
    "                max_correspondence_distance_coarse,\n",
    "                max_correspondence_distance_fine,\n",
    "            )\n",
    "            # print(\"Build o3d.pipelines.registration.PoseGraph\")\n",
    "            if target_id == source_id + 1:  # odometry case\n",
    "                odometry = np.dot(transformation_icp, odometry)\n",
    "                pose_graph.nodes.append(\n",
    "                    o3d.pipelines.registration.PoseGraphNode(\n",
    "                        np.linalg.inv(odometry)))\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=False))\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=True))\n",
    "    return pose_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align using cropped point clouds\n",
    "max_correspondence_distance_coarse = voxel_size * 4\n",
    "max_correspondence_distance_fine = voxel_size * 2\n",
    "# with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "    pose_graph = full_registration(pcds_filt,\n",
    "                                   max_correspondence_distance_coarse,\n",
    "                                   max_correspondence_distance_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizing PoseGraph ...\")\n",
    "option = o3d.pipelines.registration.GlobalOptimizationOption(\n",
    "    max_correspondence_distance=max_correspondence_distance_fine,\n",
    "    edge_prune_threshold=0.25,\n",
    "    reference_node=0\n",
    ")\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    o3d.pipelines.registration.global_optimization(\n",
    "        pose_graph,\n",
    "        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n",
    "        option\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_align = []\n",
    "for i in range(len(pcds_crop)):\n",
    "    pcd = copy.deepcopy(pcds_crop[i])\n",
    "    pcd.transform(pose_graph.nodes[i].pose)\n",
    "    pcds_align.append(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pcds_crop, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pcds_align, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pcds_align)):\n",
    "    print(np.round(pose_graph.nodes[i].pose, 3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the camera poses\n",
    "cameras = []\n",
    "for i in range(len(pcds_clean)):\n",
    "    size=voxel_size\n",
    "    if i == 0:\n",
    "        size=voxel_size*2\n",
    "    cameras.append(o3d.geometry.TriangleMesh.create_coordinate_frame(size=size))\n",
    "    cameras[i].transform(pose_graph.nodes[i].pose)\n",
    "o3d.visualization.draw_geometries(cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export for pointnerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pcds_clean and cameras\n",
    "# o3d_vis(pcds_clean_train, c2w_exts_train, align=True)\n",
    "\n",
    "pcds_clean_train = pcds_crops[0]\n",
    "o3d_vis(pcds_clean_train, c2w_exts_train, align=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x->y, y->z, z->x\n",
    "ext_rot = np.array([\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "# x->z, y->x, z->y\n",
    "ext_rot = np.array([\n",
    "    [-1, 0, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "# ext_rot = np.eye(4)\n",
    "\n",
    "# Rotate 180 degrees around x axis\n",
    "blender2cv = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, -1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fused point cloud\n",
    "pcd_fused = o3d.geometry.PointCloud()\n",
    "for i in range(len(pcds_clean_train)):\n",
    "    pcd_tmp = copy.deepcopy(pcds_clean_train[i])\n",
    "    pcd_fused += pcd_tmp\n",
    "\n",
    "# Downsample\n",
    "voxel_size = 0.05\n",
    "pcd_fused = pcd_fused.voxel_down_sample(voxel_size=voxel_size)\n",
    "pcd_fused.transform(ext_rot)\n",
    "\n",
    "# Normal estimation\n",
    "pcd_fused.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=50))\n",
    "\n",
    "pcd_fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_c2w_exts(c2w_exts):\n",
    "    c2w_exts_rot = []\n",
    "    for ext in c2w_exts:\n",
    "        c2w_exts_rot.append(ext_rot @ ext @ blender2cv)\n",
    "    return np.array(c2w_exts_rot)\n",
    "\n",
    "c2w_exts_train_rot = rotate_c2w_exts(c2w_exts_train)\n",
    "c2w_exts_val_rot = rotate_c2w_exts(c2w_exts_val)\n",
    "c2w_exts_test_rot = rotate_c2w_exts(c2w_exts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render camera poses\n",
    "origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1)\n",
    "\n",
    "cameras = []\n",
    "for i in range(len(pcds_clean_train)):\n",
    "    size=0.2\n",
    "    if i == 0:\n",
    "        size*=2\n",
    "    cameras.append(o3d.geometry.TriangleMesh.create_coordinate_frame(size=size))\n",
    "    cameras[i].transform(c2w_exts_train_rot[i])\n",
    "\n",
    "bbox = pcd_fused.get_axis_aligned_bounding_box()\n",
    "bbox.color = (1, 0, 0)\n",
    "o3d.visualization.draw_geometries(cameras + [pcd_fused, origin, bbox], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-3.995 -1.473 -3.1 1.613 1.749 1.697'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(map(\n",
    "    str,\n",
    "    list(np.round(pcd_fused.get_min_bound(), 3)) + list(np.round(pcd_fused.get_max_bound(), 3))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find camera_angle_x\n",
    "final_height = 480\n",
    "scale = final_height / color_intrinsics.height\n",
    "focal = np.mean(color_intrinsics.get_focal_length())\n",
    "print(focal, scale, focal * scale)\n",
    "focal = focal * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_angle_x = 2 * np.arctan(0.5 * final_height / focal)\n",
    "camera_angle_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 480, 640, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load/Process Data\n",
    "color_fp = os.path.join(data_folder, \"color.npy\")\n",
    "color_imgs = np.load(color_fp)\n",
    "color_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 480, 480, 3), (32, 480, 480, 3), (33, 480, 480, 3))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_imgs = color_imgs[:, :480, :480, :]\n",
    "\n",
    "color_imgs_train = color_imgs[train_idxs]\n",
    "color_imgs_val = color_imgs[val_idxs]\n",
    "color_imgs_test = color_imgs[test_idxs]\n",
    "color_imgs_train.shape, color_imgs_val.shape, color_imgs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_fp = f\"pointnerf/data_src/nerf/nerf_synthetic_colmap/{data_name.split(\"_\")[0]}\"\n",
    "!mkdir -p $folder_fp/train\n",
    "!mkdir -p $folder_fp/val\n",
    "!mkdir -p $folder_fp/test\n",
    "!mkdir -p $folder_fp/colmap_results/dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def output_data(c2w_exts, color_imgs, camera_angle_x, split=\"train\"):\n",
    "    data = {\n",
    "        \"camera_angle_x\": camera_angle_x,\n",
    "        \"frames\": []\n",
    "    }\n",
    "    for i in range(len(c2w_exts)):\n",
    "        frame = {\n",
    "            \"file_path\": f\"./{split}/r_{i}\",\n",
    "            \"rotation\": 0.0,\n",
    "            \"transform_matrix\": c2w_exts[i].tolist()\n",
    "        }\n",
    "        data[\"frames\"].append(frame)\n",
    "\n",
    "        # Save image\n",
    "        img_fp = f\"{folder_fp}/{split}/r_{i}.png\"\n",
    "        cv_img = cv2.cvtColor(color_imgs[i], cv2.COLOR_RGB2BGRA)\n",
    "        cv_img[:, :, 3] = 255\n",
    "        cv2.imwrite(img_fp, cv_img)\n",
    "\n",
    "    # Save data\n",
    "    data_fp = f\"{folder_fp}/transforms_{split}.json\"\n",
    "    with open(data_fp, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(data, outfile, indent=4)\n",
    "\n",
    "output_data(c2w_exts_train_rot, color_imgs_train, camera_angle_x, split=\"train\")\n",
    "output_data(c2w_exts_val_rot, color_imgs_val, camera_angle_x, split=\"val\")\n",
    "output_data(c2w_exts_test_rot, color_imgs_test, camera_angle_x, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "def write_ply(pcd, fp, write_text=False):\n",
    "    pts = np.asarray(pcd.points)\n",
    "    normals = np.asarray(pcd.normals)\n",
    "    colors = (np.asarray(pcd.colors) * 255).astype(np.uint8)\n",
    "\n",
    "    x, y, z = pts[:, 0], pts[:, 1], pts[:, 2]\n",
    "    nx, ny, nz = normals[:, 0], normals[:, 1], normals[:, 2]\n",
    "    r, g, b = colors[:, 0], colors[:, 1], colors[:, 2]\n",
    "    print(colors)\n",
    "\n",
    "    pts = list(zip(x, y, z, nx, ny, nz, r, g, b))\n",
    "\n",
    "    vertex = np.array(pts, dtype=[\n",
    "        ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "        ('nx', 'f4'), ('ny', 'f4'), ('nz', 'f4'),\n",
    "        ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')\n",
    "    ])\n",
    "\n",
    "    el = PlyElement.describe(vertex, 'vertex')\n",
    "    PlyData([el], text=write_text).write(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 44 45]\n",
      " [43 40 37]\n",
      " [51 45 48]\n",
      " ...\n",
      " [50 54 44]\n",
      " [43 43 38]\n",
      " [70 64 61]]\n"
     ]
    }
   ],
   "source": [
    "# Save Point Cloud\n",
    "pcd_fp = f\"{folder_fp}/colmap_results/dense/fused.ply\"\n",
    "# o3d.io.write_point_cloud(pcd_fp, pcd_fused)\n",
    "write_ply(pcd_fused, pcd_fp, write_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to = f\"pointnerf/data_src/nerf/nerf_synthetic/{data_name.split(\"_\")[0]}/\"\n",
    "!mkdir -p $copy_to\n",
    "!cp -r $folder_fp/* $copy_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points_path = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/guitar/colmap_results/dense/fused.ply\"\n",
    "points_path = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/chair/colmap_results/dense/fused.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "pcd_2 = o3d.io.read_point_cloud(points_path)\n",
    "o3d.visualization.draw_geometries([pcd_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw camera locations and rotations\n",
    "def draw_cameras(transforms_json_fp):\n",
    "    with open(transforms_json_fp, \"r\") as f:\n",
    "        transforms = json.load(f)\n",
    "\n",
    "    blender2opencv = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "    frames = transforms[\"frames\"]\n",
    "    extrinsic_matrices = [\n",
    "        np.array(frame[\"transform_matrix\"]) @ blender2opencv\n",
    "    for frame in frames]\n",
    "\n",
    "    camera_angle = transforms[\"camera_angle_x\"]\n",
    "    focal = 0.5 * 800 / np.tan(0.5 * camera_angle)\n",
    "\n",
    "    # Create dummy intrinsics\n",
    "    intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    intrinsics.set_intrinsics(512, 512, focal, focal, 256, 256)\n",
    "\n",
    "    # Draw camera locations and rotations\n",
    "    cameras = []\n",
    "    for extrinsic_matrix in extrinsic_matrices:\n",
    "        camera = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2)\n",
    "        camera.transform(extrinsic_matrix)\n",
    "        cameras.append(camera)\n",
    "    return cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_fp = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/guitar/colmap_results/dense/fused.ply\"\n",
    "transforms_json_fp = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/guitar/transforms_train.json\"\n",
    "\n",
    "gen_fps = glob.glob(\"pointnerf/checkpoints/nerfsynth/guitar/points/step-*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_fp = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/chair/colmap_results/dense/fused.ply\"\n",
    "transforms_json_fp = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/chair/transforms_train.json\"\n",
    "\n",
    "gen_fps = glob.glob(\"pointnerf/checkpoints/nerfsynth/chair/points/step-*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "colors = []\n",
    "for fp in gen_fps:\n",
    "    if not os.path.exists(fp):\n",
    "        continue\n",
    "    with open(fp, 'r') as f:\n",
    "        print(fp, len(points))\n",
    "        for line in f.readlines():\n",
    "            data = [float(x) for x in line.split(\";\")]\n",
    "            pt = np.array(data[:3])\n",
    "            color = np.array(data[3:])\n",
    "            points.append(pt)\n",
    "            colors.append(color)\n",
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pcd = o3d.geometry.PointCloud()\n",
    "gen_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "gen_pcd.paint_uniform_color([1, 0, 0])\n",
    "\n",
    "gen_bbox = gen_pcd.get_axis_aligned_bounding_box()\n",
    "gen_bbox.color = (1, 0, 0)\n",
    "\n",
    "gen_pcd.get_min_bound(), gen_pcd.get_max_bound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap_pcd = o3d.io.read_point_cloud(ply_fp)\n",
    "colmap_pcd = colmap_pcd.voxel_down_sample(voxel_size=0.02)\n",
    "colmap_pcd.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "colmap_bbox = colmap_pcd.get_axis_aligned_bounding_box()\n",
    "colmap_bbox.color = (0, 1, 0)\n",
    "\n",
    "colmap_pcd.get_min_bound(), colmap_pcd.get_max_bound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1)\n",
    "cameras = draw_cameras(transforms_json_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([\n",
    "    gen_pcd, colmap_pcd, origin, gen_bbox, colmap_bbox\n",
    "] + cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
