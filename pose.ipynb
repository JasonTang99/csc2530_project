{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import open3d as o3d\n",
    "from open3d.visualization import draw_geometries\n",
    "\n",
    "from process_bag import get_images\n",
    "from utils import get_o3d_intrinsics, colordepth_to_rgbd, rgbd_to_pcd, remove_outliers\n",
    "\n",
    "depth_intrinsics, color_intrinsics = get_o3d_intrinsics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rembg import remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chessboard size\n",
    "cb_counts = (4, 7)\n",
    "cb_scale = 2\n",
    "cb_size = 0.033 * cb_scale\n",
    "\n",
    "# Rendering settings\n",
    "voxel_size = 0.02\n",
    "camera_size = 2 * cb_size\n",
    "# origin_size = 4 * cb_size\n",
    "origin_size = 1\n",
    "\n",
    "kwargs = dict(\n",
    "    zoom=0.5,\n",
    "    front=[0.0, 0.0, -1.0],\n",
    "    lookat=[0.0, 0.0, 0.0],\n",
    "    up=[1.0, 0, 0],\n",
    ")\n",
    "kwargs = dict(\n",
    "    zoom=1.0,\n",
    "    front=[0.0, 0.0, -1.0],\n",
    "    lookat=[0.0, 0.0, 0.0],\n",
    "    up=[0, 1.0, 0],\n",
    ")\n",
    "\n",
    "data_name = \"books_2\"\n",
    "data_name_raw = data_name.split(\"_\")[0]\n",
    "data_folder = f\"data/{data_name}/\"\n",
    "\n",
    "color_fp = os.path.join(data_folder, \"color.npy\")\n",
    "depth_fp = os.path.join(data_folder, \"depth.npy\")\n",
    "color_single_fp = os.path.join(data_folder, \"color_single.npy\")\n",
    "depth_single_fp = os.path.join(data_folder, \"depth_single.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162, 480, 640, 3), (162, 480, 640), (162, 480, 640, 3), (162, 480, 640))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load/Process Data\n",
    "def get_imgs(color_fp, depth_fp, start_idx, end_idx, align=True):\n",
    "    if os.path.exists(color_fp) and os.path.exists(depth_fp):\n",
    "        color_imgs = np.load(color_fp)\n",
    "        depth_imgs = np.load(depth_fp)\n",
    "    else:\n",
    "        color_imgs = []\n",
    "        depth_imgs = []\n",
    "        fps = sorted(glob.glob(f'{data_folder}/bags/*.bag'))\n",
    "        for i, fp in enumerate(fps):\n",
    "            if not os.path.exists(fp):\n",
    "                continue\n",
    "            print(f\"Processing bag {i+1}/{len(fps)} {fp}\")\n",
    "            color_img, depth_img = get_images(\n",
    "                start_idx=start_idx,\n",
    "                end_idx=end_idx,\n",
    "                bag_fp=fp,\n",
    "                align=align,\n",
    "                median=True\n",
    "            )\n",
    "            color_imgs.append(color_img)\n",
    "            depth_imgs.append(depth_img)\n",
    "        color_imgs = np.stack(color_imgs)\n",
    "        depth_imgs = np.stack(depth_imgs)\n",
    "        np.save(color_fp, color_imgs)\n",
    "        np.save(depth_fp, depth_imgs)\n",
    "    return color_imgs, depth_imgs\n",
    "\n",
    "color_imgs, depth_imgs = get_imgs(color_fp, depth_fp, 0, 30)\n",
    "color_imgs_single, depth_imgs_single = get_imgs(\n",
    "    color_single_fp, depth_single_fp, 5, 6)\n",
    "\n",
    "color_imgs.shape, depth_imgs.shape, color_imgs_single.shape, depth_imgs_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'data/books_2/imgs/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls data/books_2/imgs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# Mkdir\n",
    "if not os.path.exists(f\"{data_folder}/imgs\"):\n",
    "    os.makedirs(f\"{data_folder}/imgs\")\n",
    "\n",
    "# Save images\n",
    "for i in range(len(color_imgs)):\n",
    "    bgr = color_imgs[i].copy()\n",
    "    bgr = cv2.cvtColor(bgr, cv2.COLOR_RGB2BGR)\n",
    "    print(bgr.shape)\n",
    "    cv2.imwrite(f\"{data_folder}/imgs/{i}.png\", bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_corners(gray, corners, size=6):\n",
    "    corners2 = cv2.cornerSubPix(gray,corners,(size, size),(-1,-1),criteria)\n",
    "    # Arrange corner order\n",
    "    x1, y1 = corners2[0, 0]\n",
    "    x2, y2 = corners2[-1, 0]\n",
    "    # print(x1, x2, y1, y2)\n",
    "    flip = False\n",
    "    if x1 > x2 or y1 < y2:\n",
    "        corners2 = corners2[::-1]\n",
    "        flip = True\n",
    "    return corners2, flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.01)\n",
    "\n",
    "# Define object points\n",
    "objp = np.zeros((cb_counts[0]*cb_counts[1],3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:cb_counts[0],0:cb_counts[1]].T.reshape(-1,2)\n",
    "objp *= cb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "used_idxs = [] # Indices of images used\n",
    "for i in tqdm(range(color_imgs.shape[0])):\n",
    "    gray = cv2.cvtColor(color_imgs[i], cv2.COLOR_RGB2GRAY)\n",
    "    gray_single = cv2.cvtColor(color_imgs_single[i], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find and refine corners\n",
    "    flags = cv2.CALIB_CB_EXHAUSTIVE + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "    ret, corners = cv2.findChessboardCornersSB(gray_single, cb_counts, flags=flags)\n",
    "    if ret == False:\n",
    "        ret, corners = cv2.findChessboardCornersSB(gray, cb_counts, flags=flags)\n",
    "    if ret == True:\n",
    "        corners, flip = finetune_corners(gray, corners)\n",
    "        if not flip:\n",
    "            print(\"Flipped\", i)\n",
    "        used_idxs.append(i)\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(used_idxs)\n",
    "print(f\"Found {n} images with checkerboard corners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_imgs = color_imgs[used_idxs]\n",
    "depth_imgs = depth_imgs[used_idxs]\n",
    "color_imgs_single = color_imgs_single[used_idxs]\n",
    "depth_imgs_single = depth_imgs_single[used_idxs]\n",
    "\n",
    "# Update files\n",
    "np.save(color_fp, color_imgs)\n",
    "np.save(depth_fp, depth_imgs)\n",
    "np.save(color_single_fp, color_imgs_single)\n",
    "np.save(depth_single_fp, depth_imgs_single)\n",
    "\n",
    "color_imgs.shape, depth_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs, titles=None, width=2):\n",
    "    if titles is not None: assert len(imgs) == len(titles)\n",
    "    f = lambda x: (x + width - 1) // width\n",
    "    n = len(imgs)\n",
    "    fig, axs = plt.subplots(f(n), width, figsize=(16, 6*f(n)))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if i >= n: break\n",
    "        ax.imshow(imgs[i])\n",
    "        if titles is not None: \n",
    "            ax.set_title(titles[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot corners\n",
    "plot_data = []\n",
    "for i in range(n):\n",
    "    try:\n",
    "        img_tmp = cv2.drawChessboardCorners(\n",
    "            color_imgs[i].copy(), cb_counts, imgpoints[i], True)\n",
    "        \n",
    "        # Calculate reprojection error\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "            [objpoints[i]], [imgpoints[i]], img_tmp.shape[:-1][::-1], None, None)\n",
    "        mat_err = np.linalg.norm(mtx - color_intrinsics.intrinsic_matrix)\n",
    "        title = f\"Image {i} {mat_err:.2f}\"\n",
    "        plot_data.append((mat_err, img_tmp, title, i))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by error and take top k\n",
    "k = 10\n",
    "plot_data.sort(key=lambda x: x[0], reverse=True)\n",
    "plot_filt = plot_data[:k]\n",
    "plot_imgs = [x[1] for x in plot_filt]\n",
    "plot_titles = [x[2] for x in plot_filt]\n",
    "plot_idxs = [x[3] for x in plot_filt]\n",
    "show_imgs(plot_imgs, plot_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, _ = color_imgs[0].shape\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "    objpoints, imgpoints, (w, h), None, None)\n",
    "\n",
    "estimated_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "estimated_intrinsics.intrinsic_matrix = mtx\n",
    "\n",
    "print(color_intrinsics.intrinsic_matrix)\n",
    "print()\n",
    "print(estimated_intrinsics.intrinsic_matrix)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, corners, imgpts):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    corner = (int(corner[0]), int(corner[1]))\n",
    "    imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "\n",
    "    img = cv2.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the negative z axis\n",
    "axis = np.float32([[1,0,0], [0,1,0], [0,0,-1]]).reshape(-1,3) * cb_size * 4\n",
    "\n",
    "rvecs_lst = []\n",
    "tvecs_lst = []\n",
    "plot_coords = []\n",
    "# for i in tqdm(range(n)):\n",
    "for i in plot_idxs:\n",
    "    try:\n",
    "        img_tmp = color_imgs[i].copy()\n",
    "\n",
    "        # Find the rotation and translation vectors.\n",
    "        rvec = rvecs[i].copy()\n",
    "        tvec = tvecs[i].copy()\n",
    "        # retval, rvec, tvec, inliers = cv2.solvePnPRansac(\n",
    "        #     objp, imgpoints[i], mtx, dist, \n",
    "        #     rvec=rvec, \n",
    "        #     tvec=tvec,\n",
    "        #     useExtrinsicGuess=True,\n",
    "        #     iterationsCount=1000,\n",
    "        #     reprojectionError=8, \n",
    "        #     confidence=0.99\n",
    "        # )\n",
    "        retval, rvec, tvec = cv2.solvePnP(\n",
    "            objp, imgpoints[i], mtx, dist, \n",
    "            rvec=rvec, \n",
    "            tvec=tvec,\n",
    "            useExtrinsicGuess=True,\n",
    "        )\n",
    "        # Check allclose\n",
    "        # print(i, np.allclose(rvec, rvecs[i]), np.allclose(tvec, tvecs[i]))\n",
    "\n",
    "        # project 3D points to image plane\n",
    "        imgpts, _ = cv2.projectPoints(axis, rvec, tvec, mtx, dist)\n",
    "        img_tmp = draw_axis(img_tmp, imgpoints[i], imgpts)\n",
    "        plot_coords.append(img_tmp)\n",
    "\n",
    "        rvecs_lst.append(rvec)\n",
    "        tvecs_lst.append(tvec)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i1, i2 = 128, 110\n",
    "# idx1, idx2 = plot_idxs.index(i1), plot_idxs.index(i2)\n",
    "# # show_imgs([plot_imgs[i], plot_imgs[i+1], plot_coords[i], plot_coords[i+1]])\n",
    "# show_imgs([plot_imgs[idx1], plot_coords[idx1], plot_imgs[idx2], plot_coords[idx2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_imgs([plot_imgs[i] for i in plot_idxs], plot_titles)\n",
    "show_imgs(plot_coords, plot_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn lists into extrinsic parameters\n",
    "# rvecs = np.array(rvecs_lst)\n",
    "# tvecs = np.array(tvecs_lst)\n",
    "rvecs = np.array(rvecs)\n",
    "tvecs = np.array(tvecs)\n",
    "\n",
    "# Turn into 4x4 extrinsic matrices\n",
    "w2c_exts = np.zeros((len(rvecs), 4, 4))\n",
    "c2w_exts = np.zeros((len(rvecs), 4, 4))\n",
    "for i in range(len(rvecs)):\n",
    "    R, _ = cv2.Rodrigues(rvecs[i])\n",
    "    w2c_exts[i, :3, :3] = R\n",
    "    w2c_exts[i, :3, 3] = tvecs[i].T\n",
    "    w2c_exts[i, 3, 3] = 1\n",
    "\n",
    "    # world to camera -> camera to world\n",
    "    c2w_exts[i] = np.linalg.inv(w2c_exts[i])\n",
    "c2w_exts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=origin_size, origin=[0,0,0])\n",
    "\n",
    "# Draw camera locations and rotations\n",
    "cameras = []\n",
    "pcds_align = []\n",
    "pcds_full = []\n",
    "\n",
    "intrinsics = color_intrinsics\n",
    "# intrinsics = estimated_intrinsics\n",
    "for c2w_ext, color_img, depth_img in zip(c2w_exts, color_imgs, depth_imgs):\n",
    "    # Get the RGBD image\n",
    "    rgbd_img = colordepth_to_rgbd(color_img, depth_img)\n",
    "    \n",
    "    # Create a camera frame\n",
    "    camera = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "        size=camera_size, origin=[0,0,0])\n",
    "    camera.transform(c2w_ext)\n",
    "\n",
    "    # Create a pointcloud\n",
    "    pcd = rgbd_to_pcd(rgbd_img, intrinsics)\n",
    "    # Scale the pointcloud\n",
    "    pcd.scale(cb_scale, center=[0,0,0])\n",
    "    pcds_full.append(pcd)\n",
    "\n",
    "    # Downsample and Align\n",
    "    pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "    pcd.transform(c2w_ext)\n",
    "    \n",
    "    # Add to lists\n",
    "    cameras.append(camera)\n",
    "    pcds_align.append(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries(\n",
    "    pcds_align + [origin] + cameras, \n",
    "    **kwargs\n",
    ")\n",
    "# draw_geometries(\n",
    "#     pcds_full + [origin] + cameras,\n",
    "#     **kwargs\n",
    "# )\n",
    "# draw_geometries(\n",
    "#     [origin] + cameras, \n",
    "#     **kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pointclouds and extrinsics\n",
    "!mkdir -p {data_folder}/plys\n",
    "!rm -rf {data_folder}/plys/*\n",
    "\n",
    "for i, (pcd, c2w_ext) in enumerate(zip(pcds_full, c2w_exts)):\n",
    "    fp = f\"{data_folder}/plys/pcd_{i:03}.ply\"\n",
    "    o3d.io.write_point_cloud(fp, pcd)\n",
    "\n",
    "np.save(f\"{data_folder}/c2w_extrinsics.npy\", c2w_exts)\n",
    "np.save(f\"{data_folder}/rvecs.npy\", rvecs)\n",
    "np.save(f\"{data_folder}/tvecs.npy\", tvecs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoise Pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_fps = sorted(glob.glob(f\"{data_folder}/plys/pcd_*.ply\"))\n",
    "\n",
    "# Seed and split into train, val, test\n",
    "np.random.seed(0)\n",
    "n = len(pcd_fps)\n",
    "idxs = np.arange(n)\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "train_percent, val_percent, test_percent = 0.6, 0.2, 0.2\n",
    "train_idxs = idxs[:int(n*train_percent)]\n",
    "val_idxs = idxs[int(n*train_percent):int(n*(train_percent+val_percent))]\n",
    "test_idxs = idxs[int(n*(train_percent+val_percent)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extrinsics\n",
    "c2w_exts = np.load(f\"{data_folder}/c2w_extrinsics.npy\")\n",
    "rvecs = np.load(f\"{data_folder}/rvecs.npy\")\n",
    "tvecs = np.load(f\"{data_folder}/tvecs.npy\")\n",
    "\n",
    "# Load the pointclouds and align\n",
    "pcds_full = []\n",
    "for i, fp in enumerate(pcd_fps):\n",
    "    pcd = o3d.io.read_point_cloud(fp)\n",
    "    # pcd.transform(c2w_exts[i])\n",
    "    pcds_full.append(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcds_train = [pcds_full[i] for i in train_idxs]\n",
    "# pcds_val = [pcds_full[i] for i in val_idxs]\n",
    "# pcds_test = [pcds_full[i] for i in test_idxs]\n",
    "\n",
    "# c2w_exts_train = c2w_exts[train_idxs]\n",
    "# c2w_exts_val = c2w_exts[val_idxs]\n",
    "# c2w_exts_test = c2w_exts[test_idxs]\n",
    "\n",
    "# len(pcds_train), len(pcds_val), len(pcds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "def o3d_vis(pcds, c2w_exts, align=True, use_kwargs=True, both=False):\n",
    "    # Test Alignment\n",
    "    pcds_align = []\n",
    "    cameras = []\n",
    "    for i in range(len(pcds)):\n",
    "        pcd = copy.deepcopy(pcds[i])\n",
    "        c2w_ext = c2w_exts[i]\n",
    "\n",
    "        if align:\n",
    "            pcd.transform(c2w_ext)\n",
    "        pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "        pcds_align.append(pcd)\n",
    "\n",
    "        # Camera frame\n",
    "        camera = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "            size=camera_size, origin=[0,0,0])\n",
    "        camera.transform(c2w_ext)\n",
    "        cameras.append(camera)\n",
    "\n",
    "    # origin coords\n",
    "    origin = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "        size=origin_size, origin=[0,0,0])\n",
    "    origin2 = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "        size=origin_size, origin=[0,0,0])\n",
    "    origin2.rotate(R=np.array([[-1,0,0],[0,-1,0],[0,0,-1]]), center=[0,0,0])\n",
    "\n",
    "    origins = [origin]\n",
    "    if both:\n",
    "        origins = [origin, origin2]\n",
    "\n",
    "    if use_kwargs:\n",
    "        o3d.visualization.draw_geometries(pcds_align + cameras + origins, \n",
    "        **kwargs)\n",
    "    else:\n",
    "        o3d.visualization.draw_geometries(pcds_align + cameras + origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_full, c2w_exts, align=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_neighbors = 20\n",
    "# std_ratio = 0.25\n",
    "# nb_points = 25\n",
    "# radius = 0.2\n",
    "\n",
    "# voxel_size = 0.02\n",
    "\n",
    "# def clean_pcds(pcds_full, c2w_exts, voxel_size=None):\n",
    "#     pcds_clean = []\n",
    "#     for i in tqdm(range(len(pcds_full))):\n",
    "#         clean = pcds_full[i]\n",
    "#         if voxel_size is not None:\n",
    "#             clean = clean.voxel_down_sample(voxel_size=voxel_size)\n",
    "        \n",
    "#         clean = remove_outliers(\n",
    "#             clean,\n",
    "#             nb_neighbors=nb_neighbors,\n",
    "#             std_ratio=std_ratio,\n",
    "#             nb_points=nb_points,\n",
    "#             radius=radius\n",
    "#         )\n",
    "#         clean.transform(c2w_exts[i])\n",
    "#         pcds_clean.append(clean)        \n",
    "#     return pcds_clean\n",
    "\n",
    "# pcds_clean_train = clean_pcds(pcds_train, c2w_exts_train, voxel_size=voxel_size)\n",
    "# pcds_clean_val = clean_pcds(pcds_val, c2w_exts_val, voxel_size=voxel_size)\n",
    "# pcds_clean_test = clean_pcds(pcds_test, c2w_exts_test, voxel_size=voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean = pcds_train[0]\n",
    "# print(clean)\n",
    "\n",
    "# nb_neighbors = 20\n",
    "# std_ratio = 0.25\n",
    "# nb_points = 25\n",
    "# radius = 0.15\n",
    "\n",
    "# voxel_size = 0.045\n",
    "\n",
    "# # Downsample\n",
    "# clean = clean.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "# clean = remove_outliers(\n",
    "#     clean,\n",
    "#     nb_neighbors=nb_neighbors,\n",
    "#     std_ratio=std_ratio,\n",
    "#     nb_points=nb_points,\n",
    "#     radius=radius\n",
    "# )\n",
    "# clean\n",
    "# draw_geometries([clean])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_full, c2w_exts, align=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define crop bounds\n",
    "# end_1 = np.array([0.04, -0.62, -0.55]) * cb_scale\n",
    "# end_2 = np.array([1.3, 0.5, 0.35]) * cb_scale\n",
    "\n",
    "# end_1 = np.array([0.2, -0.1, -0.15]) * cb_scale\n",
    "# end_2 = np.array([0.65, 0.4, 0.2]) * cb_scale\n",
    "\n",
    "end_1 = np.array([-0.2, -0.1, -0.15]) * cb_scale\n",
    "end_2 = np.array([0.65, 0.4, 0.2]) * cb_scale\n",
    "\n",
    "coord_1 = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.5, origin=[0,0,0])\n",
    "coord_2 = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.5, origin=[0,0,0])\n",
    "coord_1.translate(end_1)\n",
    "coord_2.translate(end_2)\n",
    "\n",
    "bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=end_1, max_bound=end_2)\n",
    "\n",
    "def crop_pcds(pcds, c2w_exts, bbox):\n",
    "    pcds_crops = []\n",
    "    for i, pcd in enumerate(pcds):\n",
    "        pcd_tmp = copy.deepcopy(pcd)\n",
    "        pcd_tmp.transform(c2w_exts[i])\n",
    "        pcd_tmp = pcd_tmp.crop(bbox)\n",
    "        pcd_tmp.transform(np.linalg.inv(c2w_exts[i]))\n",
    "        pcds_crops.append(pcd_tmp)\n",
    "    return pcds_crops\n",
    "\n",
    "# pcds_crop_train = crop_pcds(pcds_train, bbox)\n",
    "# pcds_crop_val = crop_pcds(pcds_val, bbox)\n",
    "# pcds_crop_test = crop_pcds(pcds_test, bbox)\n",
    "pcds_crop = crop_pcds(pcds_full, c2w_exts, bbox)\n",
    "\n",
    "# draw_geometries(pcds_crop + [coord_1, coord_2], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_crop, c2w_exts, align=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:04<00:00, 33.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Clean \n",
    "nb_neighbors = 20\n",
    "std_ratio = 0.01\n",
    "nb_points = 60\n",
    "radius = 0.1\n",
    "\n",
    "voxel_size = 0.01\n",
    "\n",
    "def clean_pcds(pcds_full, voxel_size=None):\n",
    "    pcds_clean = []\n",
    "    for i in tqdm(range(len(pcds_full))):\n",
    "        clean = pcds_full[i]\n",
    "        if voxel_size is not None:\n",
    "            clean = clean.voxel_down_sample(voxel_size=voxel_size)\n",
    "        \n",
    "        clean = remove_outliers(\n",
    "            clean,\n",
    "            nb_neighbors=nb_neighbors,\n",
    "            std_ratio=std_ratio,\n",
    "            nb_points=nb_points,\n",
    "            radius=radius\n",
    "        )\n",
    "        pcds_clean.append(clean)        \n",
    "    return pcds_clean\n",
    "\n",
    "pcds_clean = clean_pcds(pcds_crop, voxel_size=voxel_size)\n",
    "\n",
    "# Fuse the point clouds and draw bounding box\n",
    "pcd_fused_raw = o3d.geometry.PointCloud()\n",
    "for i, pcd in enumerate(pcds_clean):\n",
    "    pcd_tmp = copy.deepcopy(pcd)\n",
    "    pcd_tmp.transform(c2w_exts[i])\n",
    "    pcd_fused_raw += pcd_tmp\n",
    "\n",
    "bbox = pcd_fused_raw.get_axis_aligned_bounding_box()\n",
    "bbox.color = (1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_clean, c2w_exts, align=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.39654936, -0.19999969, -0.21016612]),\n",
       " array([1.29958914, 0.67528806, 0.39996979]))"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate all points in the bounding box defined by end_1 and end_2\n",
    "end_1 = bbox.get_min_bound()\n",
    "end_2 = bbox.get_max_bound()\n",
    "ends = []\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            ends.append([\n",
    "                end_1[0] if i == 0 else end_2[0],\n",
    "                end_1[1] if j == 0 else end_2[1],\n",
    "                end_1[2] if k == 0 else end_2[2]\n",
    "            ])\n",
    "\n",
    "ends = np.array(ends)\n",
    "end_1, end_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "ends_pcd = o3d.geometry.PointCloud()\n",
    "ends_pcd.points = o3d.utility.Vector3dVector(ends)\n",
    "ends_pcd.paint_uniform_color([0, 0, 1])\n",
    "\n",
    "draw_geometries([pcd_fused_raw, bbox, ends_pcd], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color = color_imgs[0].copy()\n",
    "# c2w = c2w_exts[0]\n",
    "# w2c = np.linalg.inv(c2w)\n",
    "# rvec, _ = cv2.Rodrigues(w2c[:3, :3])\n",
    "# tvec = w2c[:3, 3]\n",
    "\n",
    "# # projectpoints\n",
    "# imgpts, _ = cv2.projectPoints(\n",
    "#     objectPoints=ends,\n",
    "#     rvec=rvec,\n",
    "#     tvec=tvec,\n",
    "#     cameraMatrix=mtx,\n",
    "#     distCoeffs=dist\n",
    "# )\n",
    "# # Round to int\n",
    "# imgpts = np.round(imgpts).astype(np.int32)\n",
    "\n",
    "# # Draw\n",
    "# for i in range(8):\n",
    "#     color = cv2.circle(color, tuple(imgpts[i].ravel()), 5, (0,255,0), -1)\n",
    "\n",
    "# plt.imshow(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "nb_neighbors = 60\n",
    "std_ratio = 0.01\n",
    "nb_points = 60\n",
    "radius = 0.05\n",
    "\n",
    "voxel_size = 0.01\n",
    "\n",
    "pcd_fused = clean_pcds([pcd_fused_raw], voxel_size=voxel_size)[0]\n",
    "bbox = pcd_fused.get_axis_aligned_bounding_box()\n",
    "bbox.color = (1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 1508033 points.\n",
      "PointCloud with 100995 points.\n"
     ]
    }
   ],
   "source": [
    "print(pcd_fused_raw)\n",
    "print(pcd_fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries([pcd_fused, bbox], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter out points that are too bright or too gray\n",
    "# color_thresh = 0.5\n",
    "# gray_thresh = 0.07\n",
    "\n",
    "# pcds_filt = []\n",
    "# for i in range(len(pcds_crop)):\n",
    "#     pcd = pcds_crop[i]\n",
    "#     colors = np.asarray(pcd.colors)\n",
    "    \n",
    "#     color_idxs = np.where(np.mean(colors, axis=1) > color_thresh)[0]\n",
    "#     gray_idxs = np.where(np.max(colors, axis=1) - np.min(colors, axis=1) < gray_thresh)[0]\n",
    "#     idxs = np.union1d(color_idxs, gray_idxs)\n",
    "#     print(len(idxs))\n",
    "#     pcd_filt = pcd.select_by_index(\n",
    "#         idxs,\n",
    "#         invert=True\n",
    "#     )\n",
    "#     pcds_filt.append(pcd_filt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries(pcds_filt + [coord_1, coord_2], **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiway Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://www.open3d.org/docs/latest/tutorial/Advanced/multiway_registration.html\n",
    "def pairwise_registration(\n",
    "        source, target, max_correspondence_distance_coarse,\n",
    "        max_correspondence_distance_fine\n",
    "    ):\n",
    "    # print(\"Apply point-to-plane ICP\")\n",
    "    # Coarse ICP starting with identity matrix\n",
    "    icp_coarse = o3d.pipelines.registration.registration_icp(\n",
    "        source, \n",
    "        target, \n",
    "        max_correspondence_distance_coarse, \n",
    "        init = np.identity(4),\n",
    "        estimation_method = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    )\n",
    "    # Fine ICP using the result of coarse ICP as initialization\n",
    "    icp_fine = o3d.pipelines.registration.registration_icp(\n",
    "        source, \n",
    "        target, \n",
    "        max_correspondence_distance_fine,\n",
    "        init = icp_coarse.transformation,\n",
    "        estimation_method = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    )\n",
    "    \n",
    "    # Return the transformation matrix and information matrix\n",
    "    transformation_icp = icp_fine.transformation\n",
    "    information_icp = o3d.pipelines.registration.get_information_matrix_from_point_clouds(\n",
    "        source, target, max_correspondence_distance_fine,\n",
    "        icp_fine.transformation)\n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def full_registration(\n",
    "        pcds, max_correspondence_distance_coarse,\n",
    "        max_correspondence_distance_fine\n",
    "    ):\n",
    "    pose_graph = o3d.pipelines.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    for source_id in tqdm(range(n_pcds)):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(\n",
    "                pcds[source_id], \n",
    "                pcds[target_id], \n",
    "                max_correspondence_distance_coarse,\n",
    "                max_correspondence_distance_fine,\n",
    "            )\n",
    "            # print(\"Build o3d.pipelines.registration.PoseGraph\")\n",
    "            if target_id == source_id + 1:  # odometry case\n",
    "                odometry = np.dot(transformation_icp, odometry)\n",
    "                pose_graph.nodes.append(\n",
    "                    o3d.pipelines.registration.PoseGraphNode(\n",
    "                        np.linalg.inv(odometry)))\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=False))\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=True))\n",
    "    return pose_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample and compute normals\n",
    "pcds_align = []\n",
    "voxel_size = 0.015\n",
    "for i, pcd in enumerate(pcds_clean):\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "            radius=voxel_size * 2, max_nn=30))\n",
    "    pcd_down.transform(c2w_exts[i])\n",
    "    pcds_align.append(pcd_down)\n",
    "# pcds_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries(pcds_align + [coord_1, coord_2], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align using cropped point clouds\n",
    "def get_pose_graph(\n",
    "        max_correspondence_distance_coarse,\n",
    "        max_correspondence_distance_fine\n",
    "    ):\n",
    "    # with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        pose_graph = full_registration(pcds_align,\n",
    "                                    max_correspondence_distance_coarse,\n",
    "                                    max_correspondence_distance_fine)\n",
    "    return pose_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [03:12<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Align using cropped point clouds\n",
    "# pose_graph_1 = get_pose_graph(voxel_size * 8, voxel_size * 4)\n",
    "# pose_graph_2 = get_pose_graph(voxel_size * 2, voxel_size * 1)\n",
    "pose_graph_3 = get_pose_graph(voxel_size * 1, voxel_size * 0.25)\n",
    "# pose_graph_4 = get_pose_graph(voxel_size * 0.25, voxel_size * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_correspondence_distance_fine = voxel_size * 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing PoseGraph ...\n",
      "[Open3D DEBUG] Validating PoseGraph - finished.\n",
      "[Open3D DEBUG] [GlobalOptimizationLM] Optimizing PoseGraph having 162 nodes and 1327 edges.\n",
      "[Open3D DEBUG] Line process weight : 0.002617\n",
      "[Open3D DEBUG] [Initial     ] residual : 1.336365e+00, lambda : 3.667988e-02\n",
      "[Open3D DEBUG] [Iteration 00] residual : 1.328799e+00, valid edges : 1135, time : 0.034 sec.\n",
      "[Open3D DEBUG] [Iteration 01] residual : 1.326642e+00, valid edges : 1125, time : 0.023 sec.\n",
      "[Open3D DEBUG] [Iteration 02] residual : 1.326251e+00, valid edges : 1116, time : 0.022 sec.\n",
      "[Open3D DEBUG] [Iteration 03] residual : 1.326155e+00, valid edges : 1115, time : 0.021 sec.\n",
      "[Open3D DEBUG] [Iteration 04] residual : 1.326128e+00, valid edges : 1113, time : 0.021 sec.\n",
      "[Open3D DEBUG] [Iteration 05] residual : 1.326120e+00, valid edges : 1111, time : 0.021 sec.\n",
      "[Open3D DEBUG] [Iteration 06] residual : 1.326117e+00, valid edges : 1111, time : 0.022 sec.\n",
      "[Open3D DEBUG] Current_residual - new_residual < 1.000000e-06 * current_residual\n",
      "[Open3D DEBUG] [GlobalOptimizationLM] total time : 0.186 sec.\n",
      "[Open3D DEBUG] [GlobalOptimizationLM] Optimizing PoseGraph having 162 nodes and 1272 edges.\n",
      "[Open3D DEBUG] Line process weight : 0.002629\n",
      "[Open3D DEBUG] [Initial     ] residual : 1.250796e+00, lambda : 3.663796e-02\n",
      "[Open3D DEBUG] [Iteration 00] residual : 1.246715e+00, valid edges : 1099, time : 0.021 sec.\n",
      "[Open3D DEBUG] [Iteration 01] residual : 1.245713e+00, valid edges : 1096, time : 0.021 sec.\n",
      "[Open3D DEBUG] [Iteration 02] residual : 1.245547e+00, valid edges : 1096, time : 0.023 sec.\n",
      "[Open3D DEBUG] [Iteration 03] residual : 1.245505e+00, valid edges : 1094, time : 0.021 sec.\n",
      "[Open3D DEBUG] [Iteration 04] residual : 1.245492e+00, valid edges : 1094, time : 0.021 sec.\n",
      "[Open3D DEBUG] [Iteration 05] residual : 1.245487e+00, valid edges : 1092, time : 0.021 sec.\n",
      "[Open3D DEBUG] [Iteration 06] residual : 1.245484e+00, valid edges : 1092, time : 0.021 sec.\n",
      "[Open3D DEBUG] Current_residual - new_residual < 1.000000e-06 * current_residual\n",
      "[Open3D DEBUG] [GlobalOptimizationLM] total time : 0.170 sec.\n",
      "[Open3D DEBUG] CompensateReferencePoseGraphNode : reference : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimizing PoseGraph ...\")\n",
    "option = o3d.pipelines.registration.GlobalOptimizationOption(\n",
    "    max_correspondence_distance=max_correspondence_distance_fine,\n",
    "    edge_prune_threshold=0.25,\n",
    "    reference_node=0\n",
    ")\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    o3d.pipelines.registration.global_optimization(\n",
    "        # pose_graph, # 3.552442e+02,\n",
    "        # pose_graph_1, # 1.649173e+03\n",
    "        # pose_graph_2, # 2.368714e+02\n",
    "        pose_graph_3, # 5e-3, 0.123 # 1, 0.1, 1.259427e+00\n",
    "        # pose_graph_4, # 4.814716e-01\n",
    "        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n",
    "        option\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162, 3), dtype('float64'))"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import colorsys\n",
    "def get_color(red_to_green):\n",
    "    # assert 0 <= red_to_green <= 1\n",
    "    # in HSV, red is 0 deg and green is 120 deg (out of 360);\n",
    "    # divide red_to_green with 3 to map [0, 1] to [0, 1./3.]\n",
    "    hue = red_to_green / 3.0\n",
    "    r, g, b = colorsys.hsv_to_rgb(hue, 1, 1)\n",
    "    return list(map(lambda x: int(255 * x), (r, g, b)))\n",
    "# Range of colors\n",
    "x = np.linspace(0, 3, len(pcds_pose))\n",
    "colors = np.array([get_color(x_i) for x_i in x])\n",
    "colors = colors / 255.0\n",
    "colors.shape, colors.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_pose = []\n",
    "for i in range(len(pcds_align)):\n",
    "    pcd = copy.deepcopy(pcds_align[i])\n",
    "    # pcd.transform(pose_graph_1.nodes[i].pose) # no\n",
    "    # pcd.transform(pose_graph_2.nodes[i].pose) # ok\n",
    "    pcd.transform(pose_graph_3.nodes[i].pose) # \n",
    "    # pcd.transform(pose_graph_4.nodes[i].pose) #\n",
    "    # pcd.paint_uniform_color([1, 0, 0])\n",
    "    pcds_pose.append(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries(pcds_pose, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries(pcds_align, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcds_pose_2 = []\n",
    "# for i in range(len(pcds_align)):\n",
    "#     pcd = copy.deepcopy(pcds_align[i])\n",
    "#     pcd.transform(pose_graph_2.nodes[i].pose) # ok\n",
    "#     pcd.paint_uniform_color([0, 1, 0])\n",
    "#     pcds_pose_2.append(pcd)\n",
    "# draw_geometries(pcds_pose + pcds_pose_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.111\n"
     ]
    }
   ],
   "source": [
    "max_x = 0\n",
    "for i in range(len(pcds_align)):\n",
    "    # print(np.round(pose_graph.nodes[i].pose, 3))\n",
    "    # print()\n",
    "    # Print max off diagonal abs value\n",
    "    # x = np.round(np.max(np.abs(pose_graph_1.nodes[i].pose - np.diag(np.diag(pose_graph_1.nodes[i].pose)))), 3) # 0.124\n",
    "    # x = np.round(np.max(np.abs(pose_graph.nodes[i].pose - np.diag(np.diag(pose_graph.nodes[i].pose)))), 3) # 0.123\n",
    "    # x = np.round(np.max(np.abs(pose_graph_2.nodes[i].pose - np.diag(np.diag(pose_graph_2.nodes[i].pose)))), 3) # 0.122\n",
    "    x = np.round(np.max(np.abs(pose_graph_3.nodes[i].pose - np.diag(np.diag(pose_graph_3.nodes[i].pose)))), 3) # 0.111\n",
    "    # x = np.round(np.max(np.abs(pose_graph_4.nodes[i].pose - np.diag(np.diag(pose_graph_4.nodes[i].pose)))), 3) # 0.1\n",
    "    # print(x)\n",
    "    if x > max_x:\n",
    "        max_x = x\n",
    "print(max_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the camera poses\n",
    "cameras = []\n",
    "for i in range(len(pcds_clean)):\n",
    "    size=voxel_size\n",
    "    if i == 0:\n",
    "        size=voxel_size*2\n",
    "    cameras.append(o3d.geometry.TriangleMesh.create_coordinate_frame(size=size))\n",
    "    cameras[i].transform(pose_graph.nodes[i].pose)\n",
    "o3d.visualization.draw_geometries(cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w_exts = np.load(f\"{data_folder}/c2w_extrinsics.npy\")\n",
    "old_c2w = c2w_exts.copy()\n",
    "pose_graph = pose_graph_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the camera poses\n",
    "for i in range(len(pcds_clean)):\n",
    "    c2w_ext = c2w_exts[i]\n",
    "    pose = pose_graph.nodes[i].pose\n",
    "    c2w_exts[i] = pose @ c2w_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_clean, c2w_exts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_vis(pcds_clean, old_c2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align\n",
    "pcds_final = []\n",
    "for i, pcd in enumerate(pcds_clean):\n",
    "    pcds_tmp = copy.deepcopy(pcd)\n",
    "    pcds_tmp.transform(c2w_exts[i])\n",
    "    pcds_final.append(pcds_tmp)\n",
    "draw_geometries(pcds_final, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "os.system(f\"mkdir -p {data_folder}plys_final\")\n",
    "for i, pcd in enumerate(pcds_final):\n",
    "    o3d.io.write_point_cloud(f\"{data_folder}plys_final/pcd_{i}.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 40112\n",
      "-rw-rw-r-- 1 jason jason 244881 Apr 29 03:05 pcd_0.ply\n",
      "-rw-rw-r-- 1 jason jason 282250 Apr 29 03:05 pcd_100.ply\n",
      "-rw-rw-r-- 1 jason jason 269613 Apr 29 03:05 pcd_101.ply\n",
      "-rw-rw-r-- 1 jason jason 226305 Apr 29 03:05 pcd_102.ply\n",
      "-rw-rw-r-- 1 jason jason 232974 Apr 29 03:05 pcd_103.ply\n",
      "-rw-rw-r-- 1 jason jason 224091 Apr 29 03:05 pcd_104.ply\n",
      "-rw-rw-r-- 1 jason jason 210942 Apr 29 03:05 pcd_105.ply\n",
      "-rw-rw-r-- 1 jason jason 212130 Apr 29 03:05 pcd_106.ply\n",
      "-rw-rw-r-- 1 jason jason 219663 Apr 29 03:05 pcd_107.ply\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!ls -l {data_folder}plys_final | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse\n",
    "pcd_fused_raw = o3d.geometry.PointCloud()\n",
    "for i in train_idxs:\n",
    "    pcd_fused_raw += pcds_final[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 48822 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nb_neighbors = 60\n",
    "std_ratio = 0.01\n",
    "nb_points = 60\n",
    "radius = 0.05\n",
    "\n",
    "voxel_size = 0.01\n",
    "\n",
    "pcd_fused = clean_pcds([pcd_fused_raw], voxel_size=voxel_size)[0]\n",
    "bbox = pcd_fused.get_axis_aligned_bounding_box()\n",
    "bbox.color = (1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 48822 points.\n"
     ]
    }
   ],
   "source": [
    "draw_geometries([pcd_fused, bbox], **kwargs)\n",
    "print(pcd_fused)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Backgrounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from rembg import remove, new_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 480, 640, 3)"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load/Process Data\n",
    "color_imgs = np.load(color_fp)\n",
    "depth_imgs = np.load(depth_fp)\n",
    "n, h, w, c = color_imgs.shape\n",
    "n, h, w, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center crop\n",
    "crop_size = min(h, w)\n",
    "color_imgs_crop = color_imgs[:, \n",
    "    (h-crop_size)//2:(h+crop_size)//2, \n",
    "    (w-crop_size)//2:(w+crop_size)//2, \n",
    ":]\n",
    "depth_imgs_crop = depth_imgs[:,\n",
    "    (h-crop_size)//2:(h+crop_size)//2,\n",
    "    (w-crop_size)//2:(w+crop_size)//2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = new_session(\"isnet-general-use\")\n",
    "\n",
    "output_imgs = []\n",
    "max_depth = 0\n",
    "for i in tqdm(range(len(color_imgs_crop))):\n",
    "    color_img = color_imgs_crop[i].copy()\n",
    "    depth_img = depth_imgs_crop[i].copy()\n",
    "\n",
    "    # Remove background\n",
    "    color_img = remove(color_img).copy()\n",
    "    # color_img = remove(color_img, session=session).copy()\n",
    "\n",
    "    output_imgs.append(color_img)\n",
    "\n",
    "    # Alpha mask\n",
    "    alpha_mask = (color_img[:, :, 3] > alpha_thresh).astype(np.float32)\n",
    "    masked_depth = depth_img * alpha_mask\n",
    "    if masked_depth.max() > max_depth:\n",
    "        max_depth = masked_depth.max()    \n",
    "    \n",
    "max_depth, len(output_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 50\n",
    "filt_imgs = []\n",
    "for i, output_img in enumerate(output_imgs):\n",
    "    # if i < 140: continue\n",
    "    color_img = color_imgs_crop[i].copy()\n",
    "    depth_img = depth_imgs_crop[i].copy()\n",
    "    h, w, c = color_img.shape\n",
    "\n",
    "    # Alpha mask\n",
    "    alpha_mask = (output_img[:, :, 3] > alpha_thresh).astype(np.float32)\n",
    "    masked_depth = depth_img * alpha_mask\n",
    "    non_zero_masked_depth = masked_depth[masked_depth > 0].flatten()\n",
    "    n = len(non_zero_masked_depth)\n",
    "\n",
    "    # KMeans\n",
    "    # kmeans = KMeans(n_clusters=5, n_init='auto').fit(non_zero_masked_depth.reshape(-1, 1))\n",
    "    # m_lst = sorted(kmeans.cluster_centers_.flatten())\n",
    "    # depth_idx = 0\n",
    "    # while depth_idx + 1 < len(m_lst) and \\\n",
    "    #         m_lst[depth_idx] + 400 >= m_lst[depth_idx+1]:\n",
    "    #     depth_idx += 1\n",
    "    # mean_depth = m_lst[depth_idx]\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, n_init='auto').fit(non_zero_masked_depth.reshape(-1, 1))\n",
    "    m_lst = sorted(kmeans.cluster_centers_.flatten())\n",
    "    mean_depth = m_lst[0]\n",
    "\n",
    "    # Histogram\n",
    "    counts, depths = np.histogram(\n",
    "        non_zero_masked_depth, \n",
    "        bins=bins, \n",
    "        range=(0, max_depth)\n",
    "    )\n",
    "    depths = depths[1:]\n",
    "\n",
    "    # Find next 0 count\n",
    "    idx1 = 0\n",
    "    while depths[idx1] < mean_depth:\n",
    "        idx1 += 1\n",
    "    while counts[idx1]/n > 0.005:\n",
    "        idx1 += 1\n",
    "    depth_thresh_1 = depths[idx1]\n",
    "\n",
    "    # Find next non-0 count\n",
    "    idx2 = idx1\n",
    "    while idx2 < len(depths) and counts[idx2]/n < 0.0005:\n",
    "        idx2 += 1\n",
    "    if idx2 == len(depths):\n",
    "        depth_thresh_2 = depth_thresh_1\n",
    "    else:\n",
    "        depth_thresh_2 = depths[idx2]\n",
    "    p = 0.8\n",
    "    depth_thresh = p * depth_thresh_1 + (1-p) * depth_thresh_2\n",
    "    print(depth_thresh_1, depth_thresh_2, depth_thresh)\n",
    "    \n",
    "    # depth_thresh = depth_thresh_1\n",
    "\n",
    "    counts, depths = np.histogram(\n",
    "        depth_img.flatten(),\n",
    "        bins=bins,\n",
    "        range=(0, max_depth)\n",
    "    )\n",
    "    n = len(depth_img.flatten())\n",
    "    depths = depths[1:]\n",
    "    # Smooth\n",
    "    k = 10\n",
    "    counts = np.convolve(counts, np.ones(10)/10, mode='same')\n",
    "\n",
    "    idx = 0\n",
    "    while depths[idx] < depth_thresh:\n",
    "        idx += 1\n",
    "    idx += 3\n",
    "    depth_thresh = depths[idx]\n",
    "    print(depth_thresh)\n",
    "    # While decreasing, continue\n",
    "    while idx < len(depths) and counts[idx] < counts[idx-1] + 0.0001 * n:\n",
    "        idx += 1\n",
    "    depth_thresh = depths[idx-1]\n",
    "    print(depth_thresh)\n",
    "    \n",
    "    depth_mask = (depth_img <= depth_thresh).astype(np.uint8)\n",
    "    zero_mask = (depth_img > 0).astype(np.uint8)\n",
    "    mask = (depth_mask * zero_mask)\n",
    "\n",
    "    # Add alpha channel\n",
    "    color_img = np.concatenate([color_img, np.ones((h, w, 1))], axis=-1)\n",
    "    color_img[:, :, 3] = mask * 255\n",
    "    color_img = color_img.astype(np.uint8)\n",
    "    filt_imgs.append(color_img)\n",
    "\n",
    "    print(i, m_lst)\n",
    "\n",
    "    # Plot hist and img\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(color_img)\n",
    "    ax[1].plot(depths, counts)\n",
    "    ax[1].axvline(depth_thresh, color='b', linewidth=1)\n",
    "    ax[1].set_xlim(500, max_depth)\n",
    "    for m in m_lst:\n",
    "        ax[1].axvline(m, color='r', linestyle='dashed', linewidth=1)\n",
    "    plt.show()\n",
    "\n",
    "    # plt.imshow(alpha_mask)\n",
    "    # plt.imshow(masked_depth)\n",
    "    # plt.imshow(color_img)\n",
    "    # plt.show()\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 480, 480, 4)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_imgs = np.array(filt_imgs)\n",
    "filt_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "filt_fp = os.path.join(data_folder, 'filt.npy')\n",
    "np.save(filt_fp, filt_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 480, 480, 4)"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "filt_fp = os.path.join(data_folder, 'filt.npy')\n",
    "filt_imgs = np.load(filt_fp)\n",
    "filt_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/162 [00:00<00:00, 382.90it/s]\n"
     ]
    }
   ],
   "source": [
    "def denoise(img):\n",
    "    h, w, c = img.shape\n",
    "    img = img.astype(np.float32)\n",
    "    # for i in range(3):\n",
    "    #     img[:, :, i] = cv2.bilateralFilter(img[:, :, i], 5, 50, 50)\n",
    "    img[:, :, 3] = cv2.bilateralFilter(img[:, :, 3], 5, 50, 50)\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "# Denoise\n",
    "denoise_filt_imgs = []\n",
    "for i in tqdm(range(len(filt_imgs))):\n",
    "    color_img = filt_imgs[i].copy()\n",
    "    color_img = denoise(color_img)\n",
    "    denoise_filt_imgs.append(color_img)\n",
    "     \n",
    "    if i == 1:\n",
    "        # plt.imshow(color_img)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97, 480, 480, 4), (32, 480, 480, 4), (33, 480, 480, 4))"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_imgs.shape\n",
    "color_imgs_train = filt_imgs[train_idxs]\n",
    "color_imgs_val = filt_imgs[val_idxs]\n",
    "color_imgs_test = filt_imgs[test_idxs]\n",
    "color_imgs_train.shape, color_imgs_val.shape, color_imgs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_imgs_train = color_imgs_crop[train_idxs]\n",
    "# color_imgs_val = color_imgs_crop[val_idxs]\n",
    "# color_imgs_test = color_imgs_crop[test_idxs]\n",
    "# color_imgs_train.shape, color_imgs_val.shape, color_imgs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pad to original size\n",
    "# pad_size = (max(h, w) - crop_size) // 2\n",
    "# # sample = \n",
    "# plt.imshow(np.pad(color_imgs_train[0], \n",
    "#     ((0, 0), (pad_size, pad_size), (0, 0)),\n",
    "#     mode='constant',\n",
    "#     constant_values=255))\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(color_imgs[train_idxs[0]])\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export for pointnerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pcds_clean and cameras\n",
    "# o3d_vis(pcds_clean_train, c2w_exts_train, align=True)\n",
    "\n",
    "# pcds_clean_train = pcds_crops[0]\n",
    "# o3d_vis(pcds_clean_train, c2w_exts_train, align=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x->y, y->z, z->x\n",
    "ext_rot = np.array([\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "# x->z, y->x, z->y\n",
    "ext_rot = np.array([\n",
    "    [-1, 0, 0, 0.7],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "# ext_rot = np.eye(4)\n",
    "\n",
    "# Rotate 180 degrees around x axis\n",
    "blender2cv = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, -1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 32, 33)"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2w_exts_train = [c2w_exts[i] for i in train_idxs]\n",
    "c2w_exts_val = [c2w_exts[i] for i in val_idxs]\n",
    "c2w_exts_test = [c2w_exts[i] for i in test_idxs]\n",
    "len(c2w_exts_train), len(c2w_exts_val), len(c2w_exts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_c2w_exts(c2w_exts):\n",
    "    c2w_exts_rot = []\n",
    "    for ext in c2w_exts:\n",
    "        c2w_exts_rot.append(ext_rot @ ext @ blender2cv)\n",
    "    return np.array(c2w_exts_rot)\n",
    "\n",
    "# Rotate everything\n",
    "c2w_exts_train_rot = rotate_c2w_exts(c2w_exts_train)\n",
    "c2w_exts_val_rot = rotate_c2w_exts(c2w_exts_val)\n",
    "c2w_exts_test_rot = rotate_c2w_exts(c2w_exts_test)\n",
    "\n",
    "pcd_fused_rot = copy.deepcopy(pcd_fused)\n",
    "pcd_fused_rot.transform(ext_rot)\n",
    "bbox = pcd_fused_rot.get_axis_aligned_bounding_box()\n",
    "bbox.color = (1, 0, 0)\n",
    "\n",
    "# Compute normals\n",
    "pcd_fused_rot.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 2.9917691343431922)"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate furtherest camera\n",
    "furthest_cam_idx = 0\n",
    "furthest_dist = 0\n",
    "for i in range(len(pcds_clean_train)):\n",
    "    dist = np.linalg.norm(c2w_exts_train_rot[i][:3, 3])\n",
    "    if dist > furthest_dist:\n",
    "        furthest_dist = dist\n",
    "        furthest_cam_idx = i\n",
    "furthest_cam_idx, furthest_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render camera poses\n",
    "origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1)\n",
    "\n",
    "cameras = []\n",
    "for i in range(len(pcds_clean_train)):\n",
    "    size=0.2\n",
    "    if i == 0:\n",
    "        size*=2\n",
    "    cameras.append(o3d.geometry.TriangleMesh.create_coordinate_frame(size=size))\n",
    "    cameras[i].transform(c2w_exts_train_rot[i])\n",
    "\n",
    "draw_geometries(cameras + [pcd_fused_rot, origin, bbox], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4x4x4 box centered at origin\n",
    "size = 5\n",
    "box = o3d.geometry.TriangleMesh.create_box(width=size, height=size, depth=size)\n",
    "box.compute_vertex_normals()\n",
    "box.paint_uniform_color([0.9, 0.1, 0.1])\n",
    "box.translate((-size/2, -size/2, -size/2))\n",
    "\n",
    "draw_geometries([box, pcd_fused_rot] + cameras, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.409 -0.14 -0.22 1.044 0.396 0.665'"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(map(\n",
    "    str,\n",
    "    list(np.round(pcd_fused_rot.get_min_bound(), 3)) + \\\n",
    "        list(np.round(pcd_fused_rot.get_max_bound(), 3))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617.4546813964844 1.0 617.4546813964844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7414413648197282"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find camera_angle_x\n",
    "final_height = 480\n",
    "scale = final_height / color_intrinsics.height\n",
    "focal = np.mean(color_intrinsics.get_focal_length())\n",
    "print(focal, scale, focal * scale)\n",
    "focal = focal * scale\n",
    "camera_angle_x = 2 * np.arctan(0.5 * final_height / focal)\n",
    "camera_angle_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_fp = f\"pointnerf/data_src/nerf/nerf_synthetic_colmap/{data_name_raw}\"\n",
    "!mkdir -p $folder_fp/train\n",
    "!mkdir -p $folder_fp/val\n",
    "!mkdir -p $folder_fp/test\n",
    "!mkdir -p $folder_fp/colmap_results/dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def output_data(c2w_exts, color_imgs, camera_angle_x, split=\"train\"):\n",
    "    data = {\n",
    "        \"camera_angle_x\": camera_angle_x,\n",
    "        \"frames\": []\n",
    "    }\n",
    "    for i in range(len(c2w_exts)):\n",
    "        frame = {\n",
    "            \"file_path\": f\"./{split}/r_{i}\",\n",
    "            \"rotation\": 0.0,\n",
    "            \"transform_matrix\": c2w_exts[i].tolist()\n",
    "        }\n",
    "        data[\"frames\"].append(frame)\n",
    "\n",
    "        # Save image\n",
    "        img_fp = f\"{folder_fp}/{split}/r_{i}.png\"\n",
    "        cv_img = cv2.cvtColor(color_imgs[i], cv2.COLOR_RGBA2BGRA)\n",
    "        # cv_img[:, :, 3] = 255\n",
    "        cv2.imwrite(img_fp, cv_img)\n",
    "\n",
    "    # Save data\n",
    "    data_fp = f\"{folder_fp}/transforms_{split}.json\"\n",
    "    with open(data_fp, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(data, outfile, indent=4)\n",
    "\n",
    "output_data(c2w_exts_train_rot, color_imgs_train, camera_angle_x, split=\"train\")\n",
    "output_data(c2w_exts_val_rot, color_imgs_val, camera_angle_x, split=\"val\")\n",
    "output_data(c2w_exts_test_rot, color_imgs_test, camera_angle_x, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "def write_ply(pcd, fp, write_text=False):\n",
    "    pts = np.asarray(pcd.points)\n",
    "    normals = np.asarray(pcd.normals)\n",
    "    colors = (np.asarray(pcd.colors) * 255).astype(np.uint8)\n",
    "\n",
    "    x, y, z = pts[:, 0], pts[:, 1], pts[:, 2]\n",
    "    nx, ny, nz = normals[:, 0], normals[:, 1], normals[:, 2]\n",
    "    r, g, b = colors[:, 0], colors[:, 1], colors[:, 2]\n",
    "    print(len(x), len(y), len(z), len(nx), len(ny), len(nz), len(r), len(g), len(b))\n",
    "\n",
    "    pts = list(zip(x, y, z, nx, ny, nz, r, g, b))\n",
    "\n",
    "    vertex = np.array(pts, dtype=[\n",
    "        ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "        ('nx', 'f4'), ('ny', 'f4'), ('nz', 'f4'),\n",
    "        ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')\n",
    "    ])\n",
    "\n",
    "    el = PlyElement.describe(vertex, 'vertex')\n",
    "    PlyData([el], text=write_text).write(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48822 48822 48822 48822 48822 48822 48822 48822 48822\n"
     ]
    }
   ],
   "source": [
    "# Save Point Cloud\n",
    "pcd_fp = f\"{folder_fp}/colmap_results/dense/fused.ply\"\n",
    "# o3d.io.write_point_cloud(pcd_fp, pcd_fused_rot)\n",
    "write_ply(pcd_fused_rot, pcd_fp, write_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.read_point_cloud(pcd_fp)\n",
    "draw_geometries([o3d.io.read_point_cloud(pcd_fp), origin], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to = f\"pointnerf/data_src/nerf/nerf_synthetic/{data_name_raw}/\"\n",
    "!mkdir -p $copy_to\n",
    "!cp -r $folder_fp/* $copy_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 26948\n",
      "-rw-rw-r-- 1 jason jason 282377 Apr 29 03:13 r_0.png\n",
      "-rw-rw-r-- 1 jason jason 251896 Apr 29 03:13 r_10.png\n",
      "-rw-rw-r-- 1 jason jason 284394 Apr 29 03:13 r_11.png\n",
      "-rw-rw-r-- 1 jason jason 289776 Apr 29 03:13 r_12.png\n",
      "-rw-rw-r-- 1 jason jason 281271 Apr 29 03:13 r_13.png\n",
      "-rw-rw-r-- 1 jason jason 273208 Apr 29 03:13 r_14.png\n",
      "-rw-rw-r-- 1 jason jason 276860 Apr 29 03:13 r_15.png\n",
      "-rw-rw-r-- 1 jason jason 286932 Apr 29 03:13 r_16.png\n",
      "-rw-rw-r-- 1 jason jason 279111 Apr 29 03:13 r_17.png\n",
      "total 1288\n",
      "-rw-rw-r-- 1 jason jason 1318427 Apr 29 03:13 fused.ply\n",
      "total 26948\n",
      "-rw-rw-r-- 1 jason jason 282377 Apr 29 03:13 r_0.png\n",
      "-rw-rw-r-- 1 jason jason 251896 Apr 29 03:13 r_10.png\n",
      "-rw-rw-r-- 1 jason jason 284394 Apr 29 03:13 r_11.png\n",
      "-rw-rw-r-- 1 jason jason 289776 Apr 29 03:13 r_12.png\n",
      "-rw-rw-r-- 1 jason jason 281271 Apr 29 03:13 r_13.png\n",
      "-rw-rw-r-- 1 jason jason 273208 Apr 29 03:13 r_14.png\n",
      "-rw-rw-r-- 1 jason jason 276860 Apr 29 03:13 r_15.png\n",
      "-rw-rw-r-- 1 jason jason 286932 Apr 29 03:13 r_16.png\n",
      "-rw-rw-r-- 1 jason jason 279111 Apr 29 03:13 r_17.png\n",
      "total 1288\n",
      "-rw-rw-r-- 1 jason jason 1318427 Apr 29 03:13 fused.ply\n"
     ]
    }
   ],
   "source": [
    "!ls -l $folder_fp/train | head -n 10\n",
    "!ls -l $folder_fp/colmap_results/dense\n",
    "!ls -l $copy_to/train | head -n 10\n",
    "!ls -l $copy_to/colmap_results/dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points_path = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/guitar/colmap_results/dense/fused.ply\"\n",
    "points_path = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/chair/colmap_results/dense/fused.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "pcd_2 = o3d.io.read_point_cloud(points_path)\n",
    "o3d.visualization.draw_geometries([pcd_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw camera locations and rotations\n",
    "def draw_cameras(transforms_json_fp):\n",
    "    with open(transforms_json_fp, \"r\") as f:\n",
    "        transforms = json.load(f)\n",
    "\n",
    "    blender2opencv = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "    frames = transforms[\"frames\"]\n",
    "    extrinsic_matrices = [\n",
    "        np.array(frame[\"transform_matrix\"]) @ blender2opencv\n",
    "    for frame in frames]\n",
    "\n",
    "    camera_angle = transforms[\"camera_angle_x\"]\n",
    "    focal = 0.5 * 800 / np.tan(0.5 * camera_angle)\n",
    "\n",
    "    # Create dummy intrinsics\n",
    "    intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    intrinsics.set_intrinsics(512, 512, focal, focal, 256, 256)\n",
    "\n",
    "    # Draw camera locations and rotations\n",
    "    cameras = []\n",
    "    for extrinsic_matrix in extrinsic_matrices:\n",
    "        camera = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2)\n",
    "        camera.transform(extrinsic_matrix)\n",
    "        cameras.append(camera)\n",
    "    return cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_fp = f\"pointnerf/data_src/nerf/nerf_synthetic_colmap/{data_name_raw}/colmap_results/dense/fused.ply\"\n",
    "transforms_json_fp = f\"pointnerf/data_src/nerf/nerf_synthetic_colmap/{data_name_raw}/transforms_train.json\"\n",
    "\n",
    "gen_fps = glob.glob(f\"pointnerf/checkpoints/nerfsynth/{data_name_raw}/points/step-*.txt\")\n",
    "gen_fps = glob.glob(f\"pointnerf/checkpoints/col_nerfsynth/{data_name_raw}/points/step-*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ply_fp = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/chair/colmap_results/dense/fused.ply\"\n",
    "# transforms_json_fp = \"pointnerf/data_src/nerf/nerf_synthetic_colmap/chair/transforms_train.json\"\n",
    "\n",
    "# gen_fps = glob.glob(\"pointnerf/checkpoints/nerfsynth/chair/points/step-*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pointnerf/checkpoints/col_nerfsynth/books/points/step-init-0.txt 0\n",
      "pointnerf/checkpoints/col_nerfsynth/books/points/step-prob5001-0.txt 48567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50948"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "colors = []\n",
    "for fp in gen_fps:\n",
    "    if not os.path.exists(fp):\n",
    "        continue\n",
    "    with open(fp, 'r') as f:\n",
    "        print(fp, len(points))\n",
    "        for line in f.readlines():\n",
    "            data = [float(x) for x in line.split(\";\")]\n",
    "            pt = np.array(data[:3])\n",
    "            color = np.array(data[3:])\n",
    "            points.append(pt)\n",
    "            colors.append(color)\n",
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.41240132, -0.13978209, -0.22235423]),\n",
       " array([1.04215014, 0.39568877, 0.66477209]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_pcd = o3d.geometry.PointCloud()\n",
    "gen_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "gen_pcd.paint_uniform_color([1, 0, 0])\n",
    "\n",
    "gen_bbox = gen_pcd.get_axis_aligned_bounding_box()\n",
    "gen_bbox.color = (1, 0, 0)\n",
    "\n",
    "gen_pcd.get_min_bound(), gen_pcd.get_max_bound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.40851626, -0.13978209, -0.22034121]),\n",
       " array([1.04439414, 0.39568877, 0.66477209]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colmap_pcd = o3d.io.read_point_cloud(ply_fp)\n",
    "# colmap_pcd = colmap_pcd.voxel_down_sample(voxel_size=0.02)\n",
    "colmap_pcd.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "colmap_bbox = colmap_pcd.get_axis_aligned_bounding_box()\n",
    "colmap_bbox.color = (0, 1, 0)\n",
    "\n",
    "colmap_pcd.get_min_bound(), colmap_pcd.get_max_bound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1)\n",
    "cameras = draw_cameras(transforms_json_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([\n",
    "    gen_pcd, colmap_pcd, origin, gen_bbox, colmap_bbox\n",
    "] + cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([\n",
    "    gen_pcd, origin, gen_bbox, colmap_bbox\n",
    "] + cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([\n",
    "    colmap_pcd, origin, gen_bbox, colmap_bbox\n",
    "] + cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
